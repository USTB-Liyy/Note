# 大模型各种内容

## ChatGLM微调啃代码

*   使用到了p-Tuning v2，设置的soft-prompt长度为`pre_seq_len`，同时可以添加prefix（源代码没有用）。

*   前几次对话的问题和结果会作为后续问题的prompt

